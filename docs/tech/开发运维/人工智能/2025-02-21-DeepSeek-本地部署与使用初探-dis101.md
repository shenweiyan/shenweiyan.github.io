---
title: DeepSeek 本地部署与使用初探
number: 101
slug: discussions-101/
url: https://github.com/shenweiyan/Digital-Garden/discussions/101
date: 2025-02-21
authors: [shenweiyan]
categories: 
  - 1.3-折腾
labels: ['1.3.26-人工智能']
---

DeepSeek 相关的人工智能现在是火得一塌糊涂，本着学习的心态，基于现在的一些有限资源，也来体验一下。

<!-- more -->

## 参考文章

- [用本地文件调教 DeepSeek](https://mp.weixin.qq.com/s/kzwOYEMtzzBZH7jD3kNRlA)
- [ollama+open-webui，本地部署自己的大模型](https://blog.csdn.net/spiderwower/article/details/138463635)

## 注意事项

### 1. 依赖的一些问题

`open-webui` 安装完成后，在 `backend` 目录执行 `bash start.sh` 如果出现 **ImportError: libGL.so.1: cannot open shared object file: No such file or directory** 错误，可以考虑降低 `transformers` 版本，个人测试 `mamba install transformers=4.36 --force-reinstall` 重装后恢复正常。

### 2. 有限的资源，也能跑起来

一台 2 核 4G 的云服务器，跑个 **deepseek-r1:1.5b** 模型毫无压力，非常流畅，一些简单的问题也能回答出来。

![linux-deepseek-r1-1-5b](https://kg.weiyan.tech/2025/02/linux-deepseek-r1-demo.png)

### 3. 交互问题

`ollama serve`，或者 `systemctl start ollama` 默认可以通过 `http://localhost:11434` 看到 ollama 是否已经在运行，但无法与模型进行交互。《[用本地文件调教 DeepSeek](https://mp.weixin.qq.com/s/kzwOYEMtzzBZH7jD3kNRlA)》 一文说在终端运行 `ollama serve` 命令启动 Ollama 服务，服务启动后，可以通过访问 `http://localhost:11434` 来与模型进行交互。这是不正确的。          
![ollama-service-11434](https://kg.weiyan.cc/2025/02/ollama-service-11434.png)    

![ollama-is-running](https://kg.weiyan.cc/2025/02/ollama-is-running.png)

### 4. 通过网页端访问和使用。

如果想要通过网页把自己本地部署的 DeepSeek 模型开放给自己或者其他小伙伴使用，`open-webui` 是一个比较好的选择，安装和启动都很简单。
![open-webui-start](https://kg.weiyan.cc/2025/02/open-webui-start.png)   
     
![open-webui-auth](https://kg.weiyan.cc/2025/02/open-webui-auth.png)  
      
![deepseek-open-webui](https://kg.weiyan.tech/2025/02/deepseek-open-webui.png)    

<script src="https://giscus.app/client.js"
	data-repo="shenweiyan/Digital-Garden"
	data-repo-id="R_kgDOKgxWlg"
	data-mapping="number"
	data-term="101"
	data-reactions-enabled="1"
	data-emit-metadata="0"
	data-input-position="bottom"
	data-theme="light"
	data-lang="zh-CN"
	crossorigin="anonymous"
	async>
</script>
